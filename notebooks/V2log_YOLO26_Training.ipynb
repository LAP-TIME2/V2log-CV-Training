{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2log YOLO26-N Weight Plate Training (v3 â€” í†µí•©ë³¸)\n\n> **GitHub + ë°ìŠ¤í¬íƒ‘ ë…¸íŠ¸ë¶ì˜ ì¥ì ë§Œ í•©ì¹¨**\n> - âœ… Drive ZIP ë°©ì‹ (API í‚¤ ë…¸ì¶œ ì—†ìŒ, ì—°ê²° ëŠê²¨ë„ ê²°ê³¼ ì•ˆì „)\n> - âœ… ë°ì´í„° ì‹œê°í™” (í•™ìŠµ ì „ í’ˆì§ˆ í™•ì¸)\n> - âœ… ì¦ê°• íŒŒë¼ë¯¸í„° ì„¸ë¶€ ì„¤ì • (ì†ŒëŸ‰ ë°ì´í„° ëŒ€ì‘)\n> - âœ… ONNX(ê¶Œì¥) + TFLite(ë°±ì—…) ë“€ì–¼ ë‚´ë³´ë‚´ê¸°\n> - âœ… í…ŒìŠ¤íŠ¸ ê²€ì¦ + í´ë˜ìŠ¤ë³„ AP + ì˜ˆì¸¡ ì‹œê°í™”\n\n| í•­ëª© | ê°’ |\n|------|---|\n| ë°ì´í„°ì…‹ | 926ì¥ (5ê°œ í´ë˜ìŠ¤) |\n| ëª¨ë¸ | **YOLO26-N** (nano, NMS-free, CPU 43% ë¹ ë¦„) |\n| GPU | T4 (Colab ë¬´ë£Œ) |\n| ì˜ˆìƒ ì‹œê°„ | 30ë¶„~2ì‹œê°„ |\n| ê²°ê³¼ë¬¼ | `weight_plate.onnx` (Android ë©”ì¸) + `weight_plate.tflite` (ë°±ì—…) |\n\n---\n\n## ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n1. **ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ T4 GPU** ì„ íƒ\n2. Google Driveì— `V2log-CV-Training` í´ë” + ë°ì´í„°ì…‹ ZIP í™•ì¸\n3. ì…€ì„ **ìœ„ì—ì„œ ì•„ë˜ë¡œ ìˆœì„œëŒ€ë¡œ** ì‹¤í–‰ (Shift+Enter)\n\n> âš ï¸ **YOLO11 ì•„ë‹™ë‹ˆë‹¤! ë°˜ë“œì‹œ YOLO26-Nìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 1: Google Drive ì—°ê²° (30ì´ˆ)\nâ–¶ ì‹¤í–‰ â†’ íŒì—…ì—ì„œ Google ê³„ì • ì„ íƒ â†’ í—ˆìš©"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\ndrive.mount('/content/drive')\nprint('âœ… Drive ì—°ê²° ì™„ë£Œ!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 2: ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ (1ë¶„)\nDriveì— ì—…ë¡œë“œí•œ ZIPì„ Colab ë¡œì»¬ì— í’€ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import zipfile, os, glob\n\ndrive_path = '/content/drive/MyDrive/V2log-CV-Training/'\n\nif not os.path.exists(drive_path):\n    print('âŒ V2log-CV-Training í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!')\n    print('Google Driveì— V2log-CV-Training í´ë”ë¥¼ ë§Œë“¤ê³  ZIPì„ ì—…ë¡œë“œí•˜ì„¸ìš”.')\nelse:\n    zip_files = glob.glob(os.path.join(drive_path, '*.zip'))\n\n    if not zip_files:\n        print(f'âŒ {drive_path} ì— ZIP íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!')\n        print('í´ë” ì•ˆì˜ íŒŒì¼ë“¤:')\n        for f in os.listdir(drive_path):\n            print(f'  {f}')\n    else:\n        zip_path = max(zip_files, key=os.path.getmtime)\n        print(f'ğŸ“¦ ZIP ë°œê²¬: {os.path.basename(zip_path)}')\n        print('ì••ì¶• í•´ì œ ì¤‘...')\n\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall('/content/dataset')\n\n        total = 0\n        for split in ['train', 'valid', 'test']:\n            img_dir = f'/content/dataset/{split}/images'\n            if os.path.exists(img_dir):\n                count = len([f for f in os.listdir(img_dir)\n                             if f.endswith(('.jpg', '.jpeg', '.png'))])\n                total += count\n                print(f'  {split}: {count}ì¥')\n\n        print(f'\\nâœ… ì´ {total}ì¥ â€” ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 3: YOLO26 ì„¤ì¹˜ + data.yaml ê²½ë¡œ ìˆ˜ì • (1ë¶„)\n\nultralytics ìµœì‹  ë²„ì „ì´ì–´ì•¼ YOLO26-Nì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install ultralytics --upgrade -q\n\nimport ultralytics, yaml\nprint(f'ultralytics: {ultralytics.__version__}')\n\n# YOLO26 ì§€ì› í™•ì¸ (v8.4.14 ì´ìƒ í•„ìš”)\nv = ultralytics.__version__.split('.')\nmajor, minor = int(v[0]), int(v[1])\npatch = int(v[2]) if len(v) > 2 else 0\nif major >= 8 and (minor > 4 or (minor == 4 and patch >= 14)):\n    print('âœ… YOLO26-N ì§€ì› í™•ì¸!')\nelse:\n    print(f'âš ï¸ v8.4.14 ì´ìƒ í•„ìš”! í˜„ì¬ {ultralytics.__version__}')\n    print('!pip install ultralytics --upgrade ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”')\n\n# data.yaml ê²½ë¡œë¥¼ Colab í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •\nyaml_path = '/content/dataset/data.yaml'\nwith open(yaml_path, 'r') as f:\n    data = yaml.safe_load(f)\n\ndata['path'] = '/content/dataset'\ndata['train'] = 'train/images'\ndata['val'] = 'valid/images'\ndata['test'] = 'test/images'\n\nwith open(yaml_path, 'w') as f:\n    yaml.dump(data, f, default_flow_style=False)\n\nprint(f'\\ní´ë˜ìŠ¤ ìˆ˜: {data[\"nc\"]}')\nprint(f'í´ë˜ìŠ¤: {data[\"names\"]}')\nprint('\\nâœ… data.yaml ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 4: ë°ì´í„° ì‹œê°í™” â€” ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n\ní•™ìŠµ ì „ì— **ì´ë¯¸ì§€ì™€ ë¼ë²¨ì´ ì •ìƒì¸ì§€** ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.\në¬¸ì œê°€ ë³´ì´ë©´ Roboflowì—ì„œ ìˆ˜ì • í›„ ZIP ì¬ìƒì„±."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport random, os, yaml\n\nwith open('/content/dataset/data.yaml') as f:\n    data_config = yaml.safe_load(f)\nCLASS_NAMES = data_config['names']\n\nCOLORS = ['#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF',\n          '#00FFFF', '#FFA500', '#800080', '#008000']\n\ntrain_img_dir = '/content/dataset/train/images'\ntrain_lbl_dir = '/content/dataset/train/labels'\n\nall_images = [f for f in os.listdir(train_img_dir)\n              if f.endswith(('.jpg', '.jpeg', '.png'))]\nsamples = random.sample(all_images, min(8, len(all_images)))\n\nfig, axes = plt.subplots(2, 4, figsize=(20, 10))\naxes = axes.flatten()\n\nfor i, img_name in enumerate(samples):\n    img = Image.open(os.path.join(train_img_dir, img_name))\n    w, h = img.size\n    axes[i].imshow(img)\n\n    lbl_path = os.path.join(train_lbl_dir,\n                            os.path.splitext(img_name)[0] + '.txt')\n    if os.path.exists(lbl_path):\n        with open(lbl_path) as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 5:\n                    cls_id = int(parts[0])\n                    xc, yc, bw, bh = [float(x) for x in parts[1:5]]\n                    x1 = (xc - bw / 2) * w\n                    y1 = (yc - bh / 2) * h\n                    color = COLORS[cls_id % len(COLORS)]\n                    rect = patches.Rectangle(\n                        (x1, y1), bw * w, bh * h,\n                        linewidth=2, edgecolor=color, facecolor='none')\n                    axes[i].add_patch(rect)\n                    name = (CLASS_NAMES[cls_id] if isinstance(CLASS_NAMES, list)\n                            else CLASS_NAMES.get(cls_id, f'cls_{cls_id}'))\n                    axes[i].text(x1, y1 - 5, name, color=color, fontsize=8,\n                                bbox=dict(boxstyle='round,pad=0.2',\n                                          facecolor='black', alpha=0.7))\n\n    axes[i].set_title(img_name[:25], fontsize=8)\n    axes[i].axis('off')\n\nplt.suptitle('í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ (ë°”ìš´ë”© ë°•ìŠ¤ í™•ì¸)', fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# === í´ë˜ìŠ¤ë³„ ë¶„í¬ ===\nclass_counts = {}\nfor lbl_file in os.listdir(train_lbl_dir):\n    if lbl_file.endswith('.txt'):\n        with open(os.path.join(train_lbl_dir, lbl_file)) as f:\n            for line in f:\n                cls_id = int(line.strip().split()[0])\n                name = (CLASS_NAMES[cls_id] if isinstance(CLASS_NAMES, list)\n                        else CLASS_NAMES.get(cls_id, f'cls_{cls_id}'))\n                class_counts[name] = class_counts.get(name, 0) + 1\n\nprint('\\ní´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ ë¶„í¬ (train):')\nfor name, count in sorted(class_counts.items(), key=lambda x: -x[1]):\n    bar = 'â–ˆ' * (count // 3)\n    print(f'  {name:<15} {count:>4}ê°œ  {bar}')\nprint(f'\\nì´ ì–´ë…¸í…Œì´ì…˜: {sum(class_counts.values())}ê°œ')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 5: YOLO26-N í•™ìŠµ ì‹œì‘ (30ë¶„~2ì‹œê°„)\n\n**ì´ ì…€ì´ í•µì‹¬ì…ë‹ˆë‹¤!**\n\n- ì§„í–‰ ìƒí™©ì´ ì‹¤ì‹œê°„ ì¶œë ¥ë©ë‹ˆë‹¤ (Epoch 1/150, loss, mAP ë“±)\n- **Colab íƒ­ì„ ë‹«ì§€ ë§ˆì„¸ìš”!** (ì—°ê²° ëŠê¸°ë©´ í•™ìŠµ ì¤‘ë‹¨)\n- `patience=25`: 25 ì—í­ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ìë™ ì¢…ë£Œ\n- `close_mosaic=15`: ë§ˆì§€ë§‰ 15 ì—í­ì€ ëª¨ìì´í¬ ë„ê³  ì•ˆì •í™”\n- 926ì¥ ì†ŒëŸ‰ ë°ì´í„° â†’ ì¦ê°• íŒŒë¼ë¯¸í„°ë¥¼ ê°•í•˜ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤\n\n> **ë°˜ë“œì‹œ `yolo26n.pt`** â€” yolo11n.pt ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ultralytics import YOLO\n\n# ============================================\n#   YOLO26-N (ì ˆëŒ€ yolo11n ì‚¬ìš© ê¸ˆì§€!)\n# ============================================\nmodel = YOLO('yolo26n.pt')\nprint(f'ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!')\n\nresults = model.train(\n    data='/content/dataset/data.yaml',\n    epochs=150,             # ìµœëŒ€ 150 ì—í­\n    imgsz=640,              # ì´ë¯¸ì§€ í¬ê¸°\n    batch=16,               # ë°°ì¹˜ í¬ê¸° (T4: 16 ì ë‹¹)\n    device=0,               # GPU ì‚¬ìš©\n    patience=25,            # 25 ì—í­ ê°œì„  ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ\n    save=True,              # ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n    project='/content/models',\n    name='weight_plate_yolo26n',\n    exist_ok=True,\n    # === ì¦ê°• (926ì¥ ì†ŒëŸ‰ ë°ì´í„° â†’ ê°•í•˜ê²Œ) ===\n    mosaic=1.0,             # 4ì¥ í•©ì¹˜ê¸°\n    close_mosaic=15,        # ë§ˆì§€ë§‰ 15 ì—í­ì€ ëª¨ìì´í¬ OFF\n    mixup=0.15,             # ì´ë¯¸ì§€ ì„ê¸° (ê¸°ë³¸ 0.0 â†’ ì˜¬ë¦¼)\n    flipud=0.1,             # ìƒí•˜ ë°˜ì „ (ê¸°ë³¸ 0.0 â†’ ì˜¬ë¦¼)\n    fliplr=0.5,             # ì¢Œìš° ë°˜ì „\n    degrees=15.0,           # íšŒì „ Â±15ë„ (ê¸°ë³¸ 0.0 â†’ ì˜¬ë¦¼)\n    translate=0.2,          # ì´ë™ 20% (ê¸°ë³¸ 0.1 â†’ ì˜¬ë¦¼)\n    scale=0.5,              # í¬ê¸° ë³€í™”\n    hsv_h=0.015,            # ìƒ‰ìƒ ë³€í™”\n    hsv_s=0.7,              # ì±„ë„ ë³€í™”\n    hsv_v=0.4,              # ë°ê¸° ë³€í™”\n    erasing=0.4,            # ëœë¤ ì§€ìš°ê¸° (ê°€ë¦¼ ëŒ€ì‘)\n)\n\n# ê²°ê³¼ ì¶œë ¥\nmAP50 = results.results_dict.get('metrics/mAP50(B)', 0)\nmAP5095 = results.results_dict.get('metrics/mAP50-95(B)', 0)\n\nprint(f'\\n{\"=\" * 50}')\nprint(f'YOLO26-N í•™ìŠµ ì™„ë£Œ!')\nprint(f'{\"=\" * 50}')\nprint(f'mAP50:    {mAP50:.1%}')\nprint(f'mAP50-95: {mAP5095:.1%}')\n\nif mAP50 >= 0.8:\n    print('\\nâœ… 80% ì´ìƒ! ë‹¤ìŒ ì…€ë¡œ ì§„í–‰í•˜ì„¸ìš”!')\nelif mAP50 >= 0.6:\n    print('\\nâš ï¸ 60~80% â€” ë‚˜ì˜ì§€ ì•ŠìŒ. ì¼ë‹¨ ë‹¤ìŒ ì…€ ì§„í–‰.')\nelse:\n    print('\\nâŒ 60% ë¯¸ë§Œ â€” ë°ì´í„° ì¶”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 6: í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n\ní•™ìŠµ ê³¡ì„ (loss, mAP), í˜¼ë™ í–‰ë ¬, PR ê³¡ì„ ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from IPython.display import Image as IPImage, display\nimport os\n\nresult_dir = '/content/models/weight_plate_yolo26n'\n\ncharts = [\n    ('results.png', 'í•™ìŠµ ê³¡ì„  (loss + mAP)', 900),\n    ('confusion_matrix_normalized.png', 'í˜¼ë™ í–‰ë ¬ (í´ë˜ìŠ¤ë³„ ì •í™•ë„)', 600),\n    ('PR_curve.png', 'PR ê³¡ì„ ', 600),\n    ('val_batch0_pred.jpg', 'ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼', 900),\n]\n\nfor filename, desc, width in charts:\n    path = os.path.join(result_dir, filename)\n    if os.path.exists(path):\n        print(f'\\nğŸ“Š {desc}:')\n        display(IPImage(filename=path, width=width))\n    else:\n        print(f'âš ï¸ {filename} ì—†ìŒ â€” í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 7: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦ + ì˜ˆì¸¡ ì‹œê°í™”\n\ní•™ìŠµì— ì•ˆ ì“´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ **ì‹¤ì œ ì„±ëŠ¥**ì„ í™•ì¸í•©ë‹ˆë‹¤.\ní´ë˜ìŠ¤ë³„ APì™€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport random, os\n\n# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\nbest_model = YOLO('/content/models/weight_plate_yolo26n/weights/best.pt')\n\n# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ê²€ì¦\nval_results = best_model.val(\n    data='/content/dataset/data.yaml',\n    split='test',\n    imgsz=640,\n    batch=16,\n)\n\ntest_mAP50 = val_results.results_dict.get('metrics/mAP50(B)', 0)\ntest_mAP5095 = val_results.results_dict.get('metrics/mAP50-95(B)', 0)\nprecision = val_results.results_dict.get('metrics/precision(B)', 0)\nrecall = val_results.results_dict.get('metrics/recall(B)', 0)\n\nprint(f'{\"=\" * 50}')\nprint(f'í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦ ê²°ê³¼')\nprint(f'{\"=\" * 50}')\nprint(f'mAP50:     {test_mAP50:.1%}')\nprint(f'mAP50-95:  {test_mAP5095:.1%}')\nprint(f'Precision: {precision:.1%}')\nprint(f'Recall:    {recall:.1%}')\n\n# í´ë˜ìŠ¤ë³„ AP\nprint(f'\\ní´ë˜ìŠ¤ë³„ AP50:')\nif hasattr(val_results, 'box') and hasattr(val_results.box, 'ap50'):\n    names = val_results.names\n    for i in range(len(val_results.box.ap50)):\n        ap = val_results.box.ap50[i]\n        cls_name = names.get(i, f'cls_{i}') if isinstance(names, dict) else names[i]\n        status = 'âœ…' if ap >= 0.8 else 'âš ï¸' if ap >= 0.6 else 'âŒ'\n        print(f'  {status} {cls_name:<15} {ap:.1%}')\n\n# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì‹œê°í™”\ntest_img_dir = '/content/dataset/test/images'\nif os.path.exists(test_img_dir):\n    test_images = [f for f in os.listdir(test_img_dir)\n                   if f.endswith(('.jpg', '.jpeg', '.png'))]\n    if test_images:\n        samples = random.sample(test_images, min(8, len(test_images)))\n        fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n        axes = axes.flatten()\n\n        for i, img_name in enumerate(samples):\n            img_path = os.path.join(test_img_dir, img_name)\n            pred = best_model.predict(img_path, imgsz=640, conf=0.25, verbose=False)[0]\n            result_img = pred.plot()[:, :, ::-1]  # BGR â†’ RGB\n            axes[i].imshow(result_img)\n            axes[i].set_title(f'{img_name[:20]} ({len(pred.boxes)}ê°œ)', fontsize=9)\n            axes[i].axis('off')\n\n        plt.suptitle('í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼', fontsize=14)\n        plt.tight_layout()\n        plt.show()\n\nprint(f'\\n{\"=\" * 50}')\nif test_mAP50 >= 0.8:\n    print('âœ… í•©ê²©! ë‹¤ìŒ ì…€ì—ì„œ ëª¨ë¸ì„ ë‚´ë³´ë‚´ì„¸ìš”!')\nelif test_mAP50 >= 0.6:\n    print('âš ï¸ ì¤€ìˆ˜í•˜ì§€ë§Œ ê°œì„  ì—¬ì§€ ìˆìŒ')\nelse:\n    print('âŒ ë°ì´í„° ì¶”ê°€ í›„ ì¬í•™ìŠµ ê¶Œì¥')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì…€ 8: ëª¨ë¸ ë‚´ë³´ë‚´ê¸° + Google Drive ì €ì¥\n\n**YOLO26ì€ TFLiteì—ì„œ Android GPU delegate í˜¸í™˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.**\nê·¸ë˜ì„œ **ONNXë¥¼ ë©”ì¸**ìœ¼ë¡œ, TFLiteëŠ” ë°±ì—…ìš©ìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.\n\n| í˜•ì‹ | Android í˜¸í™˜ | ì—­í•  |\n|------|:-----------:|------|\n| **ONNX** | âœ… NNAPI ê°€ì† | **ë©”ì¸** |\n| TFLite | âš ï¸ GPU delegate ì´ìŠˆ | ë°±ì—… |\n\nê²°ê³¼ë¬¼ì€ **Google Driveì— ìë™ ì €ì¥**ë©ë‹ˆë‹¤ (ì—°ê²° ëŠê²¨ë„ ì•ˆì „!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ultralytics import YOLO\nimport shutil, os\n\nbest_pt = '/content/models/weight_plate_yolo26n/weights/best.pt'\nmodel = YOLO(best_pt)\n\n# ============================================\n# 1) ONNX ë‚´ë³´ë‚´ê¸° (Android ê¶Œì¥)\n# ============================================\nprint('ONNX ë³€í™˜ ì¤‘...')\nonnx_path = model.export(\n    format='onnx',\n    imgsz=640,\n    simplify=True,    # ê·¸ë˜í”„ ìµœì í™”\n    opset=17,          # ONNX opset 17\n    half=True,         # FP16\n)\nonnx_size = os.path.getsize(onnx_path) / 1024 / 1024\nprint(f'âœ… ONNX ì™„ë£Œ: {onnx_size:.1f} MB')\n\n# ============================================\n# 2) TFLite ë‚´ë³´ë‚´ê¸° (ë°±ì—…ìš©)\n# ============================================\nprint('\\nTFLite ë³€í™˜ ì¤‘... (1~3ë¶„)')\ntflite_path = None\ntry:\n    model_tflite = YOLO(best_pt)\n    tflite_path = model_tflite.export(\n        format='tflite',\n        imgsz=640,\n        half=False,    # FP32 (í˜¸í™˜ì„± ìš°ì„ )\n        int8=False,\n    )\n    tflite_size = os.path.getsize(tflite_path) / 1024 / 1024\n    print(f'âœ… TFLite ì™„ë£Œ: {tflite_size:.1f} MB')\nexcept Exception as e:\n    print(f'âš ï¸ TFLite ë³€í™˜ ì‹¤íŒ¨ (YOLO26 ì•Œë ¤ì§„ ì´ìŠˆ): {e}')\n    print('   â†’ ONNX íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš” (Android NNAPI ì§€ì›)')\n\n# ============================================\n# 3) Google Driveì— ê²°ê³¼ë¬¼ ì €ì¥\n# ============================================\ndst = '/content/drive/MyDrive/V2log-CV-Training/results_yolo26n/'\nos.makedirs(dst, exist_ok=True)\n\n# ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼\nweights_dir = '/content/models/weight_plate_yolo26n/weights/'\nfor f in os.listdir(weights_dir):\n    src = os.path.join(weights_dir, f)\n    if os.path.isfile(src):\n        shutil.copy2(src, dst)\n        size_mb = os.path.getsize(src) / (1024 * 1024)\n        print(f'  ì €ì¥: {f} ({size_mb:.1f} MB)')\n\n# ONNX íŒŒì¼ (ì´ë¦„ í†µì¼)\nif os.path.exists(onnx_path):\n    shutil.copy2(onnx_path, os.path.join(dst, 'weight_plate.onnx'))\n    print(f'  ì €ì¥: weight_plate.onnx')\n\n# TFLite íŒŒì¼ (ì´ë¦„ í†µì¼)\nif tflite_path and os.path.exists(tflite_path):\n    shutil.copy2(tflite_path, os.path.join(dst, 'weight_plate.tflite'))\n    print(f'  ì €ì¥: weight_plate.tflite')\n\n# í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„/CSV\nresult_base = '/content/models/weight_plate_yolo26n/'\nfor f in os.listdir(result_base):\n    src = os.path.join(result_base, f)\n    if os.path.isfile(src) and (f.endswith('.png') or f.endswith('.csv')):\n        shutil.copy2(src, dst)\n\nprint(f'\\n{\"=\" * 50}')\nprint(f'âœ… ëª¨ë“  ê²°ê³¼ë¬¼ Google Driveì— ì €ì¥ ì™„ë£Œ!')\nprint(f'{\"=\" * 50}')\nprint(f'ìœ„ì¹˜: Drive > V2log-CV-Training > results_yolo26n/')\nprint(f'\\nğŸ“¦ weight_plate.onnx  â†’ ì•± assets/models/ (Android ë©”ì¸)')\nif tflite_path:\n    print(f'ğŸ“¦ weight_plate.tflite â†’ assets/models/ (ë°±ì—…)')\nprint(f'ğŸ“¦ best.pt            â†’ ì¬í•™ìŠµìš© ë³´ê´€')\nprint(f'\\nğŸ‰ Phase 2A ì™„ë£Œ! â†’ Phase 2B (ì•± í†µí•©) ì‹œì‘!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## (ì„ íƒ) ì…€ 9: ì¶”ê°€ í•™ìŠµ â€” mAP50 < 80%ì¼ ë•Œë§Œ\n\nê¸°ì¡´ ê²°ê³¼ì—ì„œ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤. **ì£¼ì„(#)ì„ ì œê±°í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === ì¶”ê°€ í•™ìŠµ (ì„±ëŠ¥ ë¶€ì¡± ì‹œì—ë§Œ ì£¼ì„ ì œê±° í›„ ì‹¤í–‰) ===\n\n# from ultralytics import YOLO\n#\n# model = YOLO('/content/models/weight_plate_yolo26n/weights/best.pt')\n#\n# results = model.train(\n#     data='/content/dataset/data.yaml',\n#     epochs=50,              # ì¶”ê°€ 50 ì—í­\n#     imgsz=640,\n#     batch=16,\n#     device=0,\n#     patience=15,\n#     save=True,\n#     project='/content/models',\n#     name='weight_plate_yolo26n_ft',\n#     lr0=0.001,              # í•™ìŠµë¥  ë‚®ì¶°ì„œ ë¯¸ì„¸ ì¡°ì •\n#     close_mosaic=10,\n# )\n#\n# print(f\"mAP50: {results.results_dict.get('metrics/mAP50(B)', 0):.1%}\")\n\nprint('ì´ ì…€ì€ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.')\nprint('mAP50 < 80%ì¼ ë•Œë§Œ ì£¼ì„(#)ì„ ì œê±°í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ë¬¸ì œ í•´ê²°\n\n| ë¬¸ì œ | í•´ê²° |\n|------|------|\n| GPUê°€ ì—†ë‹¤ê³  ë‚˜ì˜´ | ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ T4 GPU |\n| Colab ì—°ê²° ëŠê¹€ | ë‹¤ì‹œ ì—°ê²° í›„ **ì…€ 5ë¶€í„°** (ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ê°) |\n| mAPê°€ ë§¤ìš° ë‚®ìŒ (<40%) | ë¼ë²¨ë§ í’ˆì§ˆ ì ê²€ (Roboflowì—ì„œ í™•ì¸) |\n| íŠ¹ì • í´ë˜ìŠ¤ë§Œ ë‚®ìŒ | í•´ë‹¹ ë¬´ê²Œ ì‚¬ì§„ 200~300ì¥ ì¶”ê°€ í›„ ì¬í•™ìŠµ |\n| TFLite ë³€í™˜ ì‹¤íŒ¨ | YOLO26 ì•Œë ¤ì§„ ì´ìŠˆ â€” ONNXë¥¼ ë©”ì¸ìœ¼ë¡œ ì‚¬ìš© |\n| ONNX ë³€í™˜ ì‹¤íŒ¨ | `!pip install -U ultralytics onnx` í›„ ì¬ì‹œë„ |\n| CUDA ë©”ëª¨ë¦¬ ë¶€ì¡± | ì…€ 5ì—ì„œ `batch=8`ë¡œ ì¤„ì´ê¸° |\n| ZIP íŒŒì¼ ëª» ì°¾ìŒ | Drive > V2log-CV-Training í´ë”ì— ZIP ìˆëŠ”ì§€ í™•ì¸ |\n\n---\n\n## ì „ì²´ íë¦„ ìš”ì•½\n\n```\nì…€ 1:  Google Drive ì—°ê²° (30ì´ˆ)\nì…€ 2:  ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ (1ë¶„)\nì…€ 3:  YOLO26 ì„¤ì¹˜ + data.yaml ìˆ˜ì • (1ë¶„)\nì…€ 4:  ë°ì´í„° ì‹œê°í™” â€” í’ˆì§ˆ í™•ì¸ â˜…\nì…€ 5:  â­ YOLO26-N í•™ìŠµ (30ë¶„~2ì‹œê°„)\nì…€ 6:  í•™ìŠµ ê²°ê³¼ ì‹œê°í™” â˜…\nì…€ 7:  í…ŒìŠ¤íŠ¸ ê²€ì¦ + í´ë˜ìŠ¤ë³„ AP â˜…\nì…€ 8:  ONNX + TFLite ë‚´ë³´ë‚´ê¸° + Drive ì €ì¥\nì…€ 9:  (ì„ íƒ) ì¶”ê°€ í•™ìŠµ\n```\n\nâ˜… = v3ì—ì„œ ìƒˆë¡œ ì¶”ê°€ëœ ì…€\n\n---\n\n**ê²€ì¦ ì¶œì²˜:**\n- [Ultralytics Train Docs](https://docs.ultralytics.com/modes/train/)\n- [Ultralytics Export Docs](https://docs.ultralytics.com/modes/export/)\n- [YOLO26 TFLite Issue #23282](https://github.com/ultralytics/ultralytics/issues/23282)\n- [PyTorch CUDA API](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_properties.html)"
   ]
  }
 ]
}